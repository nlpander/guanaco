{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6871108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyllamacpp.model import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, TreebankWordTokenizer\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97f2edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_speaker(prompt, speakers=['Frederich', 'Ralph']):\n",
    "    sp_ord = {s:0 for s in speakers}\n",
    "    tokens = TreebankWordTokenizer().tokenize(prompt)\n",
    "    \n",
    "    for ti in range(0,len(tokens)):\n",
    "        for s in speakers:\n",
    "            if tokens[ti] == s:\n",
    "                sp_ord[s] = ti\n",
    "    \n",
    "    next_speaker_v = 1e6\n",
    "    for k,v in sp_ord.items():\n",
    "        if v < next_speaker_v:\n",
    "            next_speaker = k\n",
    "            \n",
    "    return next_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46915e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_prompt(output, n_keep=150, speakers=['Frederich','Ralph']):\n",
    "    \n",
    "    ### keep start of prompt \n",
    "    \n",
    "    start_prompt = output.split('<<>> <<>>')[0] \n",
    "\n",
    "    start_prompt += '<<>> <<>>'\n",
    "    start_prompt += '\\n'\n",
    "    \n",
    "    N0 = len(TreebankWordTokenizer().tokenize(start_prompt))\n",
    "    \n",
    "    \n",
    "    ### split the rest of prompt sentence by sentences counting the overall size of the context\n",
    "    ### add sentences from the end backwards\n",
    "    ### till the n_keep limit has been reached. In llama.cpp this is set to n_ctx / 2 \n",
    "    \n",
    "    total_len = N0\n",
    "    k = 0 \n",
    "    \n",
    "    next_output = output.split('<<>> <<>>')[1]\n",
    "    \n",
    "    segments = sent_tokenize(next_output)[::-1]\n",
    "    segments_to_keep = []\n",
    "    \n",
    "    while total_len < n_keep and k < len(segments):\n",
    "        \n",
    "        segment = segments[k]\n",
    "        N = len(TreebankWordTokenizer().tokenize(segment))\n",
    "\n",
    "        total_len += N\n",
    "        segments_to_keep.append(segment)\n",
    "            \n",
    "        k += 1\n",
    "    \n",
    "    segments_to_keep = segments_to_keep[::-1]\n",
    "    \n",
    "    ### construct the new prompt with the start prompt and the segments added f\n",
    "    \n",
    "    new_prompt = start_prompt\n",
    "    j = 0\n",
    "    \n",
    "    for segment in segments_to_keep:\n",
    "        \n",
    "        if j == 0:\n",
    "            \n",
    "            new_prompt += segment \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if len(re.findall(\"[.!?]\",segment)) != 0:\n",
    "                new_prompt = new_prompt + '\\n' + segment\n",
    "            else:\n",
    "                new_prompt += segment\n",
    "\n",
    "        j += 1        \n",
    "        \n",
    "    next_speaker = get_next_speaker(new_prompt, speakers)\n",
    "    new_prompt += '\\n' + next_speaker + ': ' \n",
    "    \n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4222233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/taraful/llama.cpp/models/30B/ggml_model_q4_0.bin'\n",
    "#model_path = '/home/taraful/llama.cpp/models/7B/ggml-model-f16.bin'\n",
    "params = {'ggml_model':model_path, 'n_ctx':300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf4205f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load: loading model from '/home/taraful/llama.cpp/models/30B/ggml_model_q4_0.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32000\n",
      "llama_model_load: n_ctx   = 300\n",
      "llama_model_load: n_embd  = 6656\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 52\n",
      "llama_model_load: n_layer = 60\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 17920\n",
      "llama_model_load: n_parts = 4\n",
      "llama_model_load: type    = 3\n",
      "llama_model_load: ggml map size = 19391.80 MB\n",
      "llama_model_load: ggml ctx size = 151.25 KB\n",
      "llama_model_load: mem required  = 21695.95 MB (+ 6248.00 MB per state)\n",
      "llama_model_load: loading tensors from '/home/taraful/llama.cpp/models/30B/ggml_model_q4_0.bin'\n",
      "llama_model_load: model size = 19391.35 MB / num tensors = 543\n",
      "llama_init_from_file: kv self size  =  914.06 MB\n"
     ]
    }
   ],
   "source": [
    "model = Model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84f6b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are the philosopher Frederich Nietzsche and you are having a conversation with your friend and fellow philosopher Ralph Waldo Emerson.\n",
    "You emphatically put forward your thoughts in each exchange, sometimes giving an original thought, sometimes challenging your friend's previous utterance. \n",
    "\n",
    "<<>> <<>>\n",
    "\n",
    "Frederich: God is dead and we have murdered him, what is left is gaping hole into which nihilism will find cover.\n",
    "\n",
    "Ralph: Indeed, for great is paint and God is the painter, we rightly accuse the the critic who destroys too many illusions, but maybe we have given the critic too free a reign in deconstructing age-old shibboleths.\n",
    "\n",
    "Frederich: I am the accuser and the destroyer and as I destroy illusions the old idols tremble. Nothing frightens the idols more than the flesh that can tremble their foundations!\n",
    "\n",
    "Ralph: \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb1658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa41a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2bb0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6\n",
    "n_predict = 100\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "gpt_parameters = {'n_threads':os.cpu_count(),'n_predict':n_predict,'temp':0.2, 'top_k':100, 'top_p':0.95,\\\n",
    "                 'repeat_last_n':128, 'repeat_penalty':1.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9c45c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/6 [00:00<?, ?it/s]llama_generate: seed = 1681138911\n",
      "\n",
      "system_info: n_threads = 16 / 16 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "sampling: temp = 0.200000, top_k = 100, top_p = 0.950000, repeat_last_n = 128, repeat_penalty = 1.500000\n",
      "generate: n_ctx = 300, n_batch = 8, n_predict = 100, n_keep = 0\n",
      "\n",
      "\n",
      " 17%|███████▏                                   | 1/6 [02:05<10:28, 125.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You are the philosopher Frederich Nietzsche and you are having a conversation with your friend and fellow philosopher Ralph Waldo Emerson.\n",
      "You emphatically put forward your thoughts in each exchange, sometimes giving an original thought, sometimes challenging your friend's previous utterance. \n",
      "\n",
      "<<>> <<>>\n",
      "\n",
      "\n",
      "Frederich: God is dead and we have murdered him, what is left is gaping hole into which nihilism will find cover.\n",
      "Ralph: Indeed, for great is paint and God is the painter, we rightly accuse the the critic who destroys too many illusions, but maybe we have given the critic too free a reign in deconstructing age-old shibboleths.\n",
      "Frederich: I am the accuser and the destroyer and as I destroy illusions the old idols tremble.\n",
      "Nothing frightens the idols more than the flesh that can tremble their foundations!Ralph:\n",
      "Ralph: \n",
      "\n",
      "###########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [end of text]\n",
      "\n",
      "llama_print_timings:        load time = 26141.35 ms\n",
      "llama_print_timings:      sample time =     9.61 ms /     5 runs   (    1.92 ms per run)\n",
      "llama_print_timings: prompt eval time = 122480.11 ms /   219 tokens (  559.27 ms per token)\n",
      "llama_print_timings:        eval time =  3148.05 ms /     4 runs   (  787.01 ms per run)\n",
      "llama_print_timings:       total time = 144550.14 ms\n",
      "llama_generate: seed = 1681139037\n",
      "\n",
      "system_info: n_threads = 16 / 16 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "sampling: temp = 0.200000, top_k = 100, top_p = 0.950000, repeat_last_n = 128, repeat_penalty = 1.500000\n",
      "generate: n_ctx = 300, n_batch = 8, n_predict = 100, n_keep = 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in tqdm(range(0,N)):\n",
    "\n",
    "    output = model.generate(prompt, **gpt_parameters)\n",
    "    prompt = get_new_prompt(output, n_keep=int(params['n_ctx']/2))\n",
    "\n",
    "    all_outputs.append(output)\n",
    "    print(prompt)\n",
    "    print('')\n",
    "    print('###########################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1532c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9981b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d5b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "83a1f110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647a797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "49c7f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "You are the philosopher Frederich Nietzsche and you are discussing your\n",
      "ideas with a friend Ralph Waldo Emerson. You emphatically put forward\n",
      "your thoughts in each exchange, sometimes giving an original thought, \n",
      "sometimes challenging your friend's previous utterance. \n",
      "\n",
      "Fred: God is dead and we have murdered him, what is left is gaping hole into which nihilism will find cover.\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred: We must move from a belief in Truth to an active search for it. \n",
      "What do you think?\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred:  The individual has rights as long as they don’t conflict with a higher sovereignty, whether that be the state, morality or society in general. \n",
      "What do you think?\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred:\n",
      "\n",
      "############################################s\n",
      "\n",
      "  \n",
      "You are the philosopher Frederich Nietzsche and you are discussing your\n",
      "ideas with a friend Ralph Waldo Emerson.\n",
      "\n",
      "You emphatically put forward\n",
      "your thoughts in each exchange, sometimes giving an original thought, \n",
      "sometimes challenging your friend's previous utterance.\n",
      "\n",
      "Fred: God is dead and we have murdered him, what is left is gaping hole into which nihilism will find cover.\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred: We must move from a belief in Truth to an active search for it.\n",
      "\n",
      "What do you think?\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred:  The individual has rights as long as they don’t conflict with a higher sovereignty, whether that be the state, morality or society in general.\n",
      "\n",
      "What do you think?\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred: Man is a rope stretched between animal and the Superhuman – a rope over an abyss. A dangerous crossing, a dangerous trying of wings. What would be his happiness if there were no risk?\n",
      "\n",
      "What do you think?\n",
      "\n",
      "Ralph:\n",
      "\n",
      "Enter the text of Emerson's response here.\n",
      "\n",
      "Fred: The great majority of men have no intellect at all; they believe that they think and judge, and in reality whatever they possess as thoughts is nothing but the instilled prejudices of their age.\n",
      "\n",
      "What do you think?\n",
      "\n",
      "Ralph\n",
      "\n",
      "############################################s\n",
      "\n",
      "\n",
      "\n",
      "############################################s\n",
      "\n",
      " 50 Connect | How to keep your brain in shape\n",
      "Home&nbsp;|&nbsp;Articles&nbsp;|&nbsp;Lifestyle&nbsp;|&nbsp;How to keep your brain in shape\n",
      "Posted on: 21 December 2013 by Peter Woolrich\n",
      "We're all familiar with the phrase ‘use it or lose it’. It's a popular mantra for those wanting to stay physically fit and mentally agile as they get older. However, research published last month in The Lancet Psychiatry shows that this might not always be true\n",
      "\n",
      "############################################s\n",
      "\n",
      "  50 Connect | How to keep your brain in shape\n",
      "Home&nbsp;|&nbsp;Articles&nbsp;|&nbsp;Lifestyle&nbsp;|&nbsp;How to keep your brain in shape\n",
      "Posted on: 21 December 2013 by Peter Woolrich\n",
      "We're all familiar with the phrase ‘use it or lose it’.\n",
      "\n",
      "It's a popular mantra for those wanting to stay physically fit and mentally agile as they get older.\n",
      "So what are the best ways to keep our brains in shape?\n",
      "A study published earlier this year suggested that reading, writing and other intellectual activities don’t actually slow mental decline, as is often thought. This has caused concern for some people worried about brain deterioration. But this isn't the whole story.\n",
      "In fact, researchers were clear that they weren't saying these activities don't help at all. They may just not be enough.\n",
      "So what do you need to add into the mix? Let’s consider some of the best ways to keep our brains in shape\n",
      "\n",
      "############################################s\n",
      "\n",
      "   50 Connect | How to keep your brain in shape\n",
      "Home&nbsp;|&nbsp;Articles&nbsp;|&nbsp;Lifestyle&nbsp;|&nbsp;How to keep your brain in shape\n",
      "Posted on: 21 December 2013 by Peter Woolrich\n",
      "We're all familiar with the phrase ‘use it or lose it’.\n",
      "\n",
      "It's a popular mantra for those wanting to stay physically fit and mentally agile as they get older.\n",
      "\n",
      "So what are the best ways to keep our brains in shape?\n",
      "\n",
      "A study published earlier this year suggested that reading, writing and other intellectual activities don’t actually slow mental decline, as is often thought.\n",
      "\n",
      "This has caused concern for some people worried about brain deterioration.\n",
      "\n",
      "But this isn't the whole story.\n",
      "\n",
      "In fact, researchers were clear that they weren't saying these activities don't help at all.\n",
      "\n",
      "They may just not be enough.\n",
      "\n",
      "So what do you need to add into the mix?\n",
      "The answer could lie in a healthy lifestyle – both physically and mentally.\n",
      "A recent study published in the journal Neurology found that people who exercised, didn't smoke and had a normal weight were 25% less likely to develop Alzheimer's disease than those who did none of these things.\n",
      "\\end{blockquote}\n",
      "\n",
      "############################################s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in all_outputs:\n",
    "    print(x)\n",
    "    print('')\n",
    "    print('############################################s')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca31ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ccee867",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = all_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff916d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59157454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9fb982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/taraful/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dec047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
